---
title: 'Test d hypothèse : un exemple (suite)'
author: "Lucas Mello Schnorr, Jean-Marc Vincent"
date: "March 14, 2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Paradox Presentation

People from Florence, Italy, played many games a long time ago. Among these games, there was one that consisted in summing up the numbers that were obtained when three dices were throw. The duke of Tuscany, whom certainly have observed many three-dice throws, have reached the conclusion that the sum equals to 10 was more observed than the sum equals to 9. The paradox, presented to Galileo by the Duke, resides that there is the same amount of times to write 10 and 9 as the sum of three integers between 1 and 6.

Indeed, there are 6 ways to write 9 as the sum of three 6-facet dices:
        1+2+6, 1+3+5, 1+4+4, 2+2+5, 2+3+4, 3+3+3
and there are also 6 ways to write 10:
        1+3+6, 1+4+5, 2+2+6, 2+3+5, 2+4+4, 3+3+4

### Experiments 

Building the simulation environment:

```{r}
library(dplyr);
library(ggplot2);
library(gridExtra);
```


#### The Dice

Let's build a function to work as a generator of a dice called =Dice(k, n)=, where k is the number of facets, and the n is the number of times the dice is throw. So, when Dice is called, it returns n times an independent variable that follows the uniform law between 1 and k.


```{r}
dice <- function(k = 6, n = 100)
{
  sample(x = seq(from = 1, to = k, by = 1), size=n, replace=TRUE);
}

# generate 10 numbers of a dice with 6 facets
dice(6,10)
```

### The Three-Dice experiment of the Duke of Tuscany

We generate a sample of n observations from three dices:

```{r}
experiment <- function (k = 6, n = 100)
{
  set.seed(42)
  dice1 <- dice(k, n);
  dice2 <- dice(k, n);
  dice3 <- dice(k, n);

  data.frame(Dice1 = dice1,
             Dice2 = dice2,
             Dice3 = dice3);
}
# generate an experiment with 5 throws of three dices of 6 k
experiment(6,5)
```

#### Sum of the three dices, repartition

We generate a experiment and calculate the sum of the three dices.

We then calculate the number of occurrences of each possible value of the sum.

```{r}
experiment(6,1000) %>% 
  mutate(Sum = Dice1 + Dice2 + Dice3) %>% 
  group_by(Sum) %>% 
  summarize(N=n());
```

We do the empirical (observed) visualization of the probabilities.

Try to do with different sample sizes. What we can observe?

```{r}
Toscane <- function(k =6, n = 100)
{
  experiment(k,n) %>%
    mutate(Sum = Dice1 + Dice2 + Dice3) %>%
    ggplot(aes(x=as.factor(Sum))) +
    geom_bar(aes(y = (..count..)/sum(..count..)), width = .3) +
    xlab("Valeur de la somme")+ylab ("Fréquence") +
    ggtitle(paste("Taille de l'échantillon : ",n)) +
    # à modifier pour adapter et utiliser les facets
    ylim (0, 0.15) +
    theme_bw()
}
list(10,100,1000,10000,100000,1000000) %>%
lapply(function(taille) {
  Toscane( n = taille )
}) %>%
grid.arrange(ncol = 2,grobs=.);

```

#### Compute the estimation error

The dependency on the sample size.

```{r,fig.height=5}

Toscane_9_10_erreur <-function(k = 6, n = 471, Confiance = 0.95 )
{
  Phi_alpha= qnorm(1-(1-Confiance)/2) ;

  experiment(k,n) %>%
    mutate(Sum = Dice1 + Dice2 + Dice3,Taille=n()) %>%
    group_by(Sum,Taille) %>%
    summarize(N=n()) %>%
    mutate(Freq=N/Taille) %>%
    mutate(Ecart_type_Estime=sqrt(Freq*(1-Freq)),
         Erreur=Phi_alpha*Ecart_type_Estime/sqrt(Taille)) %>%
    filter((Sum == 9)|(Sum == 10))%>%
    ggplot(aes(x=Freq,xmin=Freq-Erreur,xmax=Freq+Erreur,y=as.factor(Sum))) +
    geom_point()+
    geom_errorbarh(height=.3)+
    xlab("Fréquence")+ylab ("Val") +
    xlim(0,0.3)+
    labs(title = paste("Taille de l'échantillon :",n,"Confiance :",Confiance)  )+
#    ylim (, ) +
    theme_bw()
}

list(100,1000,10000,100000,1000000) %>%
lapply(function(taille) {
  Toscane_9_10_erreur( n = taille , Confiance = 0.9)
}) %>%
grid.arrange(ncol = 1,grobs=.);

```

```{r,fig.height=5}

Toscane_9_10_erreur <-function(k = 6, n = 1000, Confiance = 0.95 )
{
  Phi_alpha= qnorm(1-(1-Confiance)/2) ;

  experiment(k,n) %>%
    mutate(Sum = Dice1 + Dice2 + Dice3,Taille=n()) %>%
    group_by(Sum,Taille) %>%
    summarize(N=n()) %>%
    mutate(Freq=N/Taille) %>%
    mutate(Ecart_type_Estime=sqrt(Freq*(1-Freq)),
         Erreur=Phi_alpha*Ecart_type_Estime/sqrt(Taille)) %>%
    filter((Sum == 9)|(Sum == 10))%>%
    ggplot(aes(x=Freq,xmin=Freq-Erreur,xmax=Freq+Erreur,y=as.factor(Sum))) +
    geom_point()+
    geom_errorbarh(height=.3)+
    xlab("Fréquence")+ylab ("Val") +
    xlim(0,0.2)+
    labs(title = paste("Taille de l'échantillon :",n,"Confiance :",Confiance)  )+
#    ylim (, ) +
    theme_bw()
}
list(0.9,0.95,0.99,0.999) %>%
lapply(function(Param_Confiance) {
  Toscane_9_10_erreur( n = 100000 , Confiance = Param_Confiance)
}) %>%
grid.arrange(ncol = 1,grobs=.);

```

### Theory

In the paradox of the Duke of Tuscany, we can model the problem and compute the different probabilities.

#### Model

We model the problem by representing the throws of three dices by three random variables $X_1,X_2,X_3$, which are independent and identically distributed between $\{1,2\cdots,6\}$. So, for 
$0\leq k \leq 6$
\[
\mathbb{P}(X_i=k)=\frac 16 \text{ pour } i\in\{1,2,3\} ;
\]
and for $0\leq k_1,k_2,k_3 \leq 6$
\[
\mathbb{P}(X_1=k_1,X_2=k_2,X_3=k_3)= \mathbb{P}(X_1=k_1)\mathbb{P}(X_2=k_2)\mathbb{P}(X_3=k_3)=\frac 1 {6^3}.
\]
We obtain the uniform law in the set $\{1,2,3,4,5,6\}^3$.

We observe that $S= X_1+X_2+X_3$ is the random variable representing the sum of three dices. We can take a look in the set of triplets chosen in $\{1,2,3,4,5,6\}^3$ and  count the number of triplets of sum $k$ with $0\leq k\leq 18$.

```{r}
k = 6 ;

d = data.frame();
for (de1 in seq(1,k)){
 for (de2 in seq(1,k)){
   for (de3 in seq(1,k)){
     d <<- rbind(d, data.frame(Dice1 = de1, Dice2 = de2, Dice3 = de3));
   }
 }
}

d %>%
 mutate(Sum=Dice1+Dice2+Dice3, Total=n()) %>%
 group_by(Sum, Total) %>%
 summarize(N = n()) %>%
 ungroup () %>%
 mutate(P = N/sum(N)) -> d_theorique;

ggplot(data=d_theorique, aes(x=as.factor(Sum), y = P)) +
    geom_point(color = "red") +
    xlab("Valeur de la somme")+ylab ("Probabilité") +
    ggtitle("Probabilité théorique") +
    # à modifier pour adapter et utiliser les facets
    ylim (0, NA) +
    theme_bw()
```

On reprend les expériences précédentes et on prend les histogrammes pour différentes tailles d'échantillons

```{r,fig.height=15}
Toscane_avec_theorie <- function(k =6, n = 100)
{
  experiment(k,n) %>%
    mutate(Sum = Dice1 + Dice2 + Dice3) %>%
    ggplot(aes(x=as.factor(Sum))) +
    geom_point(data=d_theorique, aes(x=as.factor(Sum), y = P), shape = 21, colour = "red", fill = "white", size = 2, stroke = 3)+
    geom_bar(aes(y = (..count..)/sum(..count..)), width = .3) +
    xlab("Valeur de la somme")+ylab ("Fréquence") +
    ggtitle(paste("Taille de l'échantillon : ",n)) +
    # à modifier pour adapter et utiliser les facets
    ylim (0, NA) +
    theme_bw()
}

list(10,100,1000,10000,100000,1000000) %>%
lapply(function(taille) {
  Toscane_avec_theorie( n = taille )
}) %>%
grid.arrange(ncol = 2,grobs=.)
```

### What can we conclude?

The methodological error proposed in the Duke of Tuscany is to suppose that all configurations of values of dices, here in the example of three dices, has the same probability. In our case, we can compute all combinations (exercise: do it and by ordering have the number of sets of three values and their sum).

The set of three values have not the same probability of appearing in the result:

9 as a sum of three dices: 1+2+6 (6 triplets), 1+3+5 (6), 1+4+4 (3), 2+2+5 (3), 2+3+4 (6), 3+3+3 (1) 

10 as a sum of three dices: 1+3+6 (6), 1+4+5 (6), 2+2+6 (3), 2+3+5 (6), 2+4+4 (3), 3+3+4 (3)

For example 1+2+6 can be obtained with the triplets (1,2,6)  (1,6,2) (2,1,6) (2,6,1) (6,1,2) (6,2,1).

The probability of observing 9 (10 respectively) is $p_9= \frac {25}{6^3}=0.1157$ (respectively $p_{10}= \frac {27}{6^3}=0.1250$). We observe that $p_9 < p_{10}$ like it was supposed by the Duke of Tuscany. The difference between these two probabilities is $\frac 2 {6^3}=0.0093\simeq 1\%$, something small.

The Duke explained his conviction by observation, and certainly he has made many throws. Indeed, we can see that by considering such confidence intervals at least a sample size of 100000 throws are necessary to separate $p_9$ et $p_10$ with a confidence interval of 95%. 

By conducing so much observations, the Duke would not miss the "natural" fluctuations in the estimation of probabilities $P_9$ et $p_10$. 

So, we need to suppose that dices used in the 100000 throws were identical, without bias, and that the probability of each face is $\frac 16$ with an error sufficiently inferior à $1%$ (in reality, it is hard to manufacture non-biased dices). So, it was indeed very difficult to answer to the paradox with experiments.

How to understand this situation? We can come back to the context, of the XVI century, the mathematicians were able to established their reputation by launching challenges. For example, Girolamo Cardano (1501 - 1576) has kept secret his resolution method of equations of third degree (in the form $x^3+ax^2+bx+c=0$) to resolve problems that other mathematicions were incapable to resolve (for example you can read the book _La formule secrète - le duel mathématique qui enflamma l'Italie de la Renaissance  de Fabio Toscano, edition Belin 2011_). We could think that the Duke of Tuscany challenged the Galileo in the experiment terrain, by secretly knowing the theoretical results, without having the statistical tools that will appear only later in the XVIII century (the law of errors of Moivre and Laplace) and then in the XVIII century with Gauss.

We could think that Galileo, using this paradox as pedagogical introduction, would like to give an aristocratic caractere to the question and strenghten the demonstration the usefulness of the analytical calculus instead of a purely experimental approach. We let this matter to the historians of science.

